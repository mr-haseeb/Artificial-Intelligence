{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of data-piplines",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mr-haseeb/Artificial-Intelligence/blob/master/Copy_of_data_piplines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfJRIsdU5cPC",
        "colab_type": "text"
      },
      "source": [
        "# Importing Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QaF7jK4iNsLY",
        "colab": {}
      },
      "source": [
        "!pip install pymysql\n",
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from tensorflow.keras import layers\n",
        "import bert\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "from sqlalchemy import create_engine\n",
        "import pymysql\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4X88JsSz5gPx",
        "colab_type": "text"
      },
      "source": [
        "# Fetching Data from MySQL Database"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3gsoJeKINr7U",
        "colab": {}
      },
      "source": [
        "sqlEngine= create_engine('mysql+pymysql://collab:Collab2020@@51.15.95.84', pool_recycle=3600)\n",
        "dbConnection= sqlEngine.connect()\n",
        "df= pd.read_sql(\"select subject as senderaddress,JSON_EXTRACT(folderlabel, '$[0]')  AS target from socialhuman.emails WHERE  1=1 ORDER BY datetime ASC, RAND() LIMIT 5000\", dbConnection);\n",
        "df.head(10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lUMeEH165mmU",
        "colab_type": "text"
      },
      "source": [
        "# Spliting and Encoding Categorical Features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "motrwADwHeyL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_encoder = preprocessing.LabelEncoder()\n",
        "df['targetB'] = label_encoder.fit_transform(df['target'])\n",
        "df['senderaddress']= pd.Series(df['senderaddress'], dtype=\"string\")\n",
        " \n",
        "# X = (np.array(df['senderaddress']))\n",
        "y = (np.array(df['targetB']))\n",
        "\n",
        " \n",
        "X = df['senderaddress']\n",
        "# y = df['targetB']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=13)\n",
        "print(\"Train dataset shape: {0}, \\nTest dataset shape: {1}\".format(X_train.shape, X_test.shape))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9NQ_wS5p9AnI",
        "colab_type": "text"
      },
      "source": [
        "# Cleaning Text Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTe03_EW9Din",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_text(sen):\n",
        "    # Removing html tags\n",
        "    sentence = remove_tags(sen)\n",
        "\n",
        "    # Remove punctuations and numbers\n",
        "    sentence = re.sub('[^a-zA-Z]', ' ', sentence)\n",
        "\n",
        "    # Single character removal\n",
        "    sentence = re.sub(r\"\\s+[a-zA-Z]\\s+\", ' ', sentence)\n",
        "\n",
        "    # Removing multiple spaces\n",
        "    sentence = re.sub(r'\\s+', ' ', sentence)\n",
        "\n",
        "    return sentence\n",
        "    \n",
        "TAG_RE = re.compile(r'<[^>]+>')\n",
        "\n",
        "def remove_tags(text):\n",
        "    return TAG_RE.sub('', text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7VfJEhXw9PYo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "clean_text = []\n",
        "sentences = list(X)\n",
        "for sen in sentences:\n",
        "    clean_text.append(preprocess_text(sen))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OmolzZbHOMbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(clean_text[3])\n",
        "print(y[3])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmGyemFW5t_x",
        "colab_type": "text"
      },
      "source": [
        "# Creating a BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DuIXh_pqGzHK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocabulary_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "to_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocabulary_file, to_lower_case)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AP_lBgIO-Pe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizing_text(text):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6K2ZekimO8oB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized_text = [tokenizing_text(text) for text in clean_text]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XMHfmw2QgXP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(tokenized_text)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsPgegPWQttO",
        "colab_type": "text"
      },
      "source": [
        "# Prerparing Data For Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWe542vtQrwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "text_with_len = [[text, y[i], len(text)] for i, text in enumerate(tokenized_text)]\n",
        "random.shuffle(text_with_len)\n",
        "text_with_len.sort(key=lambda x: x[2])\n",
        "\n",
        "\n",
        "sorted_text_labels = [(text_lab[0], text_lab[1]) for text_lab in text_with_len]\n",
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_text_labels, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19iGxqJBTN1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))\n",
        "next(iter(batched_dataset))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFwSGO8KTdHY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp58ThfwTaB2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TOTAL_BATCHES = math.ceil(len(sorted_text_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IXHxkdaTmUA",
        "colab_type": "text"
      },
      "source": [
        "# Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onfFEL3YTlBI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TEXT_MODEL(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=13,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(TEXT_MODEL, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1) # (batch_size, 3 * cnn_filters)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jt-M7zY6VcSC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "\n",
        "DROPOUT_RATE = 0.2\n",
        "\n",
        "NB_EPOCHS = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3UVjYc6LVkG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_model = TEXT_MODEL(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faQ_NmevVrCI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BySb1HvwVxAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_model.fit(train_data, epochs=NB_EPOCHS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KW_ifUFBahp3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# callbacks = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy',mode='max')\n",
        "# history = model.fit(train_ds, epochs=2, validation_data=valid_ds)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2eLQk7jPJVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "history_dict = bert_history.history\n",
        "history_dict.keys()\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmoF3w3x6s33",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate the model\n",
        "And let's see how the model performs. Two values will be returned. Loss (a number which represents our error, lower values are better), and accuracy.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw71HRZe6wCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = model.evaluate(test_data.batch(512), verbose=2)\n",
        "for name, value in zip(model.metrics_names, results):\n",
        "  print(\"%s: %.3f\" % (name, value))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MpzCXynbPRrC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = range(1, len(acc) + 1)\n",
        "\n",
        "# \"bo\" is for \"blue dot\"\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "# b is for \"solid blue line\"\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HnPg6FTGPQ3H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.clf()   # clear figure\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAtqdvEScJK5",
        "colab_type": "text"
      },
      "source": [
        "# Add inputs: way 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7pRfKLoET4c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "@tf.function(input_signature=[tf.TensorSpec([None,], tf.string)])\n",
        "\n",
        "def classify(asunto):\n",
        "  classes = etiquetas.classes_\n",
        "  softmax = tf.math.softmax(model(asunto))\n",
        "  scores, indices = tf.math.top_k(softmax, k=2)\n",
        "  classes = tf.gather(classes, indices)\n",
        " \n",
        "  return {'item': asunto, 'classes': classes, 'scores' : scores}\n",
        "\n",
        "signatures={'classify': classify}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjMUfVASdgt5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MODEL_DIR = F'/modelos/'\n",
        "import os \n",
        "version=6\n",
        "##modulemodel = MyModule(new_model)\n",
        "export_path = os.path.join(MODEL_DIR, str(version))\n",
        "\n",
        "\n",
        "tf.saved_model.save(    model,    export_path      ,signatures)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3StczY6d8NV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " my_reviews=['this movie was awesome',\n",
        "           'LinkedIn <messages-noreply@linkedin.com> was awesome',\n",
        "           'I hated everything about this movie',\n",
        "           'this is my favorite movie of the year']\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6IfUcTTdyAg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#loaded_model=tf.keras.models.load_model('modelclasificaemails.h5')\n",
        "loaded_model = tf.saved_model.load(export_path)\n",
        "\n",
        "print(list(loaded_model.signatures.keys()))\n",
        "DEFAULT_FUNCTION_KEY = \"serving_default\"\n",
        "infer = loaded_model.signatures[\"classify\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VypY492Or99m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "infer(tf.convert_to_tensor(my_reviews))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qlC9-Kx5uP1S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!saved_model_cli show --dir '{export_path}' --all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsjyzDtEv4Mt",
        "colab_type": "text"
      },
      "source": [
        "# Installing requirements for TensorFlow Serve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CrXRsueXv_Pq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!echo \"deb http://storage.googleapis.com/tensorflow-serving-apt stable tensorflow-model-server tensorflow-model-server-universal\" | tee /etc/apt/sources.list.d/tensorflow-serving.list && \\\n",
        "curl https://storage.googleapis.com/tensorflow-serving-apt/tensorflow-serving.release.pub.gpg | apt-key add -\n",
        "!apt update\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNSxTRwlwAOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get install tensorflow-model-server"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W-HSVhQIwFjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.environ[\"MODEL_DIR\"] = MODEL_DIR\n",
        "print(MODEL_DIR)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZgB5i4LwTbE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%bash --bg \n",
        "nohup tensorflow_model_server \\\n",
        "  --rest_api_port=8505 \\\n",
        "  --model_name=modelos \\\n",
        "  --model_base_path=\"${MODEL_DIR}\" >server.log 2>&1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PChcfvNTwVja",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tail server.log"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yziFDkmFwk3c",
        "colab_type": "text"
      },
      "source": [
        "# Making REST Request"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LyeaQAbaGVK_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!curl http://localhost:8505/v1/models/modelos"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZvXLA23MwowP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q requests\n",
        "\n",
        "import requests\n",
        "import json\n",
        "data = json.dumps({\"signature_name\": \"classify\", \"instances\": my_reviews})\n",
        "print('Data: {} ... {}'.format(data[:50], data[len(data)-52:]))\n",
        "headers = {\"content-type\": \"application/json\"}\n",
        "json_response = requests.post('http://localhost:8505/v1/models/modelos:predict', data=data, headers=headers)\n",
        "print(json_response.content.decode())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OkTZJO_V3RQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}